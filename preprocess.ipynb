{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5v0o1zddSoll",
   "metadata": {
    "id": "5v0o1zddSoll",
    "outputId": "d044cdf5-78c8-404c-b244-cbde39bba4a8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neurokit2 in /home/peep/anaconda3/envs/cn/lib/python3.9/site-packages (0.1.5)\n",
      "Requirement already satisfied: scikit-learn in /home/peep/anaconda3/envs/cn/lib/python3.9/site-packages (from neurokit2) (0.24.2)\n",
      "Requirement already satisfied: matplotlib in /home/peep/anaconda3/envs/cn/lib/python3.9/site-packages (from neurokit2) (3.4.2)\n",
      "Requirement already satisfied: pandas in /home/peep/anaconda3/envs/cn/lib/python3.9/site-packages (from neurokit2) (1.3.2)\n",
      "Requirement already satisfied: numpy in /home/peep/anaconda3/envs/cn/lib/python3.9/site-packages (from neurokit2) (1.19.5)\n",
      "Requirement already satisfied: scipy in /home/peep/anaconda3/envs/cn/lib/python3.9/site-packages (from neurokit2) (1.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/peep/anaconda3/envs/cn/lib/python3.9/site-packages (from matplotlib->neurokit2) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/peep/anaconda3/envs/cn/lib/python3.9/site-packages (from matplotlib->neurokit2) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/peep/anaconda3/envs/cn/lib/python3.9/site-packages (from matplotlib->neurokit2) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/peep/anaconda3/envs/cn/lib/python3.9/site-packages (from matplotlib->neurokit2) (8.3.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/peep/anaconda3/envs/cn/lib/python3.9/site-packages (from matplotlib->neurokit2) (1.3.1)\n",
      "Requirement already satisfied: six in /home/peep/anaconda3/envs/cn/lib/python3.9/site-packages (from cycler>=0.10->matplotlib->neurokit2) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/peep/anaconda3/envs/cn/lib/python3.9/site-packages (from pandas->neurokit2) (2021.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/peep/anaconda3/envs/cn/lib/python3.9/site-packages (from scikit-learn->neurokit2) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/peep/anaconda3/envs/cn/lib/python3.9/site-packages (from scikit-learn->neurokit2) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install neurokit2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e0b34d4",
   "metadata": {
    "id": "2e0b34d4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import neurokit2 as nk\n",
    "from scipy.io import loadmat  # this is the module that loads mat-files\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15, 8]\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "655c1620",
   "metadata": {
    "id": "655c1620"
   },
   "outputs": [],
   "source": [
    "def remove_baseline(df):\n",
    "    df[\"signal_horizontal_nk\"] = nk.signal_detrend(df[\"signal_horizontal\"], method=\"locreg\", window=1.5*1000, stepsize=0.05*1000)\n",
    "    df[\"signal_vertical_nk\"] = nk.signal_detrend(df[\"signal_vertical\"], method=\"locreg\", window=1.5*1000, stepsize=0.05*1000)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def read_file_into_df(f_name):\n",
    "    \"\"\" \n",
    "    Reads data from one .mat file into a DataFrame.\n",
    "    Expects data files to be in the root/data_raw folder. \n",
    "    \"\"\"\n",
    "    \n",
    "    mat = loadmat(f\"data_raw/{f_name}\")\n",
    "    df = pd.DataFrame(mat['data'])\n",
    "    df.columns = ['time_sec', 'time_microsec', 'signal_horizontal', 'signal_vertical', 'class']\n",
    "    \n",
    "    df['time_full'] = df['time_sec'] + (df['time_microsec'] / 1_000_000)\n",
    "    #df['time_full_str'] = df['time_full_str'].astype(str)\n",
    "    df = df[['time_sec','time_microsec','time_full','signal_horizontal','signal_vertical','class']]\n",
    "\n",
    "    return df\n",
    "\n",
    "def read_all_files():\n",
    "    \"\"\"\n",
    "    Reads all data files into DataFrames and puts them into a 2D dictionary.\n",
    "    To access a file, the first key is the participant (1 - 8), second key is the experiment (0, 1).\n",
    "    Example: to get the data from the first experiment of participant 5, use dict[5][0]\n",
    "    \"\"\"\n",
    "    \n",
    "    d = {}\n",
    "    \n",
    "    for participant in range(1, 9):\n",
    "        d[participant] = {}\n",
    "        \n",
    "        for experiment in range(0, 2):\n",
    "            d[participant][experiment] = remove_baseline(read_file_into_df(f\"participant{participant}_{experiment}.mat\"))\n",
    "    return d\n",
    "\n",
    "def all_datasets_read_correctly(d):\n",
    "    \"\"\" Checks if all datasets were read correctly (all datasets contain all classes). \"\"\"\n",
    "    \n",
    "    nr_of_datasets = 0\n",
    "    \n",
    "    for p in range(1, 9): # participant\n",
    "        p_dict = d[p]\n",
    "    \n",
    "        for e in range(0, 2): # experiment\n",
    "            e_dict = p_dict[e]\n",
    "            labels = e_dict['class'].unique()\n",
    "            \n",
    "            for c in range(1, 9): # class label\n",
    "                if c not in labels:\n",
    "                    print(f\"Class {c} not found in participant {p} experiment {e}!\")\n",
    "                    return\n",
    "            nr_of_datasets += 1\n",
    "    print(\"Looks good! All experiments contain all classes.\")\n",
    "    print(f\"Total {nr_of_datasets} datasets from 16 experiments.\")\n",
    "    \n",
    "def print_dataset_sizes(d):\n",
    "    for participant, exps in d.items():\n",
    "        for experiment, data in exps.items():\n",
    "            print(f\"participant:{participant}   experiment:{experiment}   total rows:{len(data.index)}\")\n",
    "            \n",
    "            for class_label in range(1, 9):\n",
    "                df_class = data[data['class'] == class_label]\n",
    "                print(f\"\\t\\t     class:{class_label}   nr of rows:{len(df_class.index)}\")\n",
    "                \n",
    "            print()\n",
    "            \n",
    "def machine_measuring_consistency(d):\n",
    "    stds = np.array([])\n",
    "    means = np.array([])\n",
    "\n",
    "    for participant, exps in d.items():\n",
    "        for experiment, data in exps.items():\n",
    "            print(f\"participant:{participant}   experiment:{experiment}\")\n",
    "\n",
    "            for class_label in range(1, 9):\n",
    "                class_df = data[data['class'] == class_label]\n",
    "                measurements = np.asarray(class_df['time_full'])\n",
    "                helper = np.insert(measurements, 0, 0)\n",
    "\n",
    "                last = measurements[-1]\n",
    "                measurements = np.append(measurements, last)\n",
    "\n",
    "                timediffs = np.asarray(measurements - helper)[1:-1]\n",
    "                std = round(np.std(timediffs), 4)\n",
    "                mean = round(np.mean(timediffs), 4)\n",
    "                print(f\"\\tclass:{class_label}   measuring time std:{std} (sec)   mean:{mean} (sec)\")\n",
    "                stds = np.append(stds, std)\n",
    "                means = np.append(means, mean)\n",
    "            print()\n",
    "\n",
    "    print(f\"Mean std: {np.mean(stds)}\")\n",
    "    print(f\"Mean mean: {np.mean(means)}\")\n",
    "    \n",
    "def plot_column_with_class_colors(x, y, dataset_dict, participant, experiment, col_name):\n",
    "    color_dict = {1:'darkorange', \n",
    "                  2:'lime', \n",
    "                  3:'red', \n",
    "                  4:'cyan', \n",
    "                  5:'magenta', \n",
    "                  6:'darkgoldenrod', \n",
    "                  7:'black', \n",
    "                  8:'gold'}\n",
    "    colors = [color_dict[class_] for class_ in dataset_dict[participant][experiment]['class']]\n",
    "    plt.scatter(x, y, s=0.1, c=colors)\n",
    "    plt.legend(handles=[mpatches.Patch(color=color, label=class_) for class_, color in color_dict.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dce7d6ca",
   "metadata": {
    "id": "dce7d6ca",
    "outputId": "a316cc52-87b4-45cb-bf5c-53ed330dc1fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================\n",
      "\n",
      "\n",
      "=========================================\n",
      "\n",
      "On average, 187k rows of data per experiment, 23k per class.\n",
      "\n",
      "=========================================\n",
      "\n",
      "Average standard deviation of the gap between each measurement in each class of each experiment\n",
      "\n",
      "\n",
      "=========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Most of this notebook is commented out to so all of that code wouldn't run when importing the functions to other notebooks\n",
    "\n",
    "\n",
    "\n",
    "# Reads all datasets into 2D dict.\n",
    "# First key is participant nr (1 - 8), second is experiment nr (0, 1)\n",
    "#dataset_dict = read_all_files()\n",
    "\n",
    "# Example use\n",
    "#participant1_experiment0_data = dataset_dict[1][0]\n",
    "\n",
    "# Do all datasets contain all classes?\n",
    "#all_datasets_read_correctly(dataset_dict)\n",
    "print('\\n=========================================\\n')\n",
    "\n",
    "# Data sample, columns, and their datatypes\n",
    "#print(f\"Participant 1 experiment 0 data sample:\\n\\n{participant1_experiment0_data.head(5)}\\n\")\n",
    "#print(f\"Columns and their data types: \\n{participant1_experiment0_data.dtypes}\")\n",
    "print('\\n=========================================\\n')\n",
    "\n",
    "# Sizes of datasets.\n",
    "# Smallest class size belongs to participant 1, experiment 0, class 7; has only 398 rows\n",
    "#print_dataset_sizes(dataset_dict)\n",
    "print('On average, 187k rows of data per experiment, 23k per class.')\n",
    "print('\\n=========================================\\n')\n",
    "\n",
    "# How consistent the machine's measuring time was?\n",
    "print('Average standard deviation of the gap between each measurement in each class of each experiment\\n')\n",
    "#machine_measuring_consistency(dataset_dict)\n",
    "print('\\n=========================================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb9d44ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print measurment amounts of given participant and experiment\n",
    "p, e = 1, 0\n",
    "#times = dataset_dict[p][e][dataset_dict[p][e]['class'] == 2]['time_sec'].unique()\n",
    "\n",
    "#for el in times:\n",
    "    #print(len(dataset_dict[p][e][dataset_dict[p][e]['time_sec'] == el].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7646c99b",
   "metadata": {
    "id": "7646c99b",
    "outputId": "00473d09-6c1d-4db4-85f5-2cfc6d3dde9a"
   },
   "outputs": [],
   "source": [
    "# For checking how classes are arranged in a dataset\n",
    "participant, experiment, col_name = 1, 0, 'signal_horizontal_nk'\n",
    "\n",
    "#plot_column_with_class_colors(x = np.arange(0, len(dataset_dict[participant][experiment][col_name].index), 1),\n",
    "                              #y = dataset_dict[participant][experiment][col_name],\n",
    "                              #dataset_dict = dataset_dict,\n",
    "                              #participant = participant,\n",
    "                              #experiment = experiment,\n",
    "                              #col_name = col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9q3L9KLCSol9",
   "metadata": {
    "id": "9q3L9KLCSol9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "preprocess.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
