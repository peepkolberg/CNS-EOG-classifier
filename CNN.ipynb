{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdOeRB9alHpk",
        "outputId": "893a5c5e-2a9f-460a-e04f-209dff80f38c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipynb in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Cloning into 'CNS-EOG-classifier'...\n",
            "remote: Enumerating objects: 40, done.\u001b[K\n",
            "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 40 (delta 7), reused 34 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (40/40), done.\n",
            "/content/CNS-EOG-classifier/CNS-EOG-classifier\n"
          ]
        }
      ],
      "source": [
        "# Clone from GitHub to Colab\n",
        "!pip install ipynb # to import functions from other ipynb files\n",
        "!git clone https://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@github.com/peepkolberg/CNS-EOG-classifier.git\n",
        "%cd CNS-EOG-classifier/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from ipynb.fs.full.preprocess import read_file_into_df # import the function to read .mat data into DataFrame\n",
        "\n",
        "from keras.layers import Conv1D, Dense, Dropout, Input, Concatenate, GlobalMaxPooling1D\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "VMaQwxAKm47A"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_split(df, chunk_size):\n",
        "  \"\"\"\n",
        "  Input: DataFrame\n",
        "  Outputs: NumPy arrays of data and labels\n",
        "\n",
        "  Splits time-series data into equal-sized chunks. \n",
        "  \"\"\"\n",
        "\n",
        "  X = []\n",
        "  y = []\n",
        "\n",
        "  for label in df['class'].unique():\n",
        "    class_df = df[df['class'] == label]\n",
        "\n",
        "    piece = []\n",
        "\n",
        "    for sig_h, sig_v in zip(class_df['signal_horizontal'], class_df['signal_vertical']):\n",
        "      piece.append(np.asarray((sig_h, sig_v)))\n",
        "\n",
        "    piece = np.asarray(piece)\n",
        "\n",
        "    for i in range(0, len(piece), chunk_size): \n",
        "      X.append(np.asarray(piece[i:i + chunk_size]))\n",
        "      y.append(label)\n",
        "\n",
        "    del X[-1]\n",
        "    del y[-1]\n",
        "\n",
        "  X = np.asarray(X)\n",
        "  y = np.asarray(y) - 1 # Subtracting 1 because original labels are 1, ..., 8 but CNN wants them to start from 0.\n",
        "\n",
        "  return X, y"
      ],
      "metadata": {
        "id": "zTKt08HWOrtI"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use one dataset for training, one for testing.\n",
        "df_train = read_file_into_df(f_name = 'participant1_1.mat')\n",
        "df_test = read_file_into_df(f_name = 'participant1_0.mat')\n",
        "\n",
        "# Not sure if this is even necassary\n",
        "df_train['class'] = df_train['class'].astype('category')\n",
        "df_test['class'] = df_test['class'].astype('category')"
      ],
      "metadata": {
        "id": "QoQfziP0n0G3"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split both DataFrames into multiple chunks.\n",
        "X_train, y_train = data_split(df_train, chunk_size = 100)\n",
        "X_test, y_test = data_split(df_test, chunk_size = 100)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rERHk6MDMAO",
        "outputId": "9a69a32f-4a43-44cd-cdac-6e7e7aa4434c"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(880, 250, 2)\n",
            "(892, 250, 2)\n",
            "(880,)\n",
            "(892,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = Input(shape = X_train.shape[1:])\n",
        "c1 = Conv1D(32, 5, padding=\"valid\", activation=\"sigmoid\")(i)\n",
        "p1 = GlobalMaxPooling1D()(c1)\n",
        "d1 = Dense(50, activation=\"sigmoid\")(p1)\n",
        "d1 = Dropout(0.3)(d1)\n",
        "o = Dense(8, activation='softmax')(d1)\n",
        "model = Model(i, o)\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "#model.summary()\n",
        "\n",
        "history = model.fit(X_train, y_train, batch_size = 25, epochs=10, validation_data = (X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlFBLdXKoDdJ",
        "outputId": "554f2c72-86e4-4db6-898e-8748576773e5"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "36/36 [==============================] - 1s 15ms/step - loss: 2.1310 - accuracy: 0.1523 - val_loss: 1.9483 - val_accuracy: 0.1536\n",
            "Epoch 2/10\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 1.9972 - accuracy: 0.1807 - val_loss: 1.9103 - val_accuracy: 0.1536\n",
            "Epoch 3/10\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 1.9877 - accuracy: 0.1716 - val_loss: 1.8949 - val_accuracy: 0.1536\n",
            "Epoch 4/10\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 1.9899 - accuracy: 0.1614 - val_loss: 1.8930 - val_accuracy: 0.1536\n",
            "Epoch 5/10\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 1.9392 - accuracy: 0.1716 - val_loss: 1.8884 - val_accuracy: 0.1536\n",
            "Epoch 6/10\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 1.9743 - accuracy: 0.1670 - val_loss: 1.8894 - val_accuracy: 0.1536\n",
            "Epoch 7/10\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 1.9621 - accuracy: 0.1602 - val_loss: 1.8884 - val_accuracy: 0.1536\n",
            "Epoch 8/10\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 1.9736 - accuracy: 0.1716 - val_loss: 1.8877 - val_accuracy: 0.1536\n",
            "Epoch 9/10\n",
            "36/36 [==============================] - 0s 10ms/step - loss: 1.9361 - accuracy: 0.1761 - val_loss: 1.8856 - val_accuracy: 0.1536\n",
            "Epoch 10/10\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 1.9236 - accuracy: 0.1750 - val_loss: 1.8840 - val_accuracy: 0.1536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7JLFDDefqPLf"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_bJoch6xu72s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}